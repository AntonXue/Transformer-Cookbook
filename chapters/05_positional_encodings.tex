%-----------------------------------
%
\chapter{Positional Encodings}
%
%-----------------------------------

Many different kinds of ingredients here.

\section{Sinusoidal}

We present the sinusoidal position encodings as was introduced in~\citep{vaswani-etal-2017-attention}.
For embedding dimension \(1 \leq i \leq d\) and position \(p\), let:
\begin{align*}
    \msf{PE}(p, 2i) = \sin\left(\frac{p}{M^{2i/d}}\right),
    \quad
    \msf{PE}(p, 2i+1) = \cos\left(\frac{p}{M^{2i/d}}\right)
\end{align*}
where \(M\) is a large number, such as \(M = 10000\) in~\citep{vaswani-etal-2017-attention}.

\subsection{Rotary Positional Embeddings (RoPE)}
\cite{su2024roformer}


\section{Finite Image}

\section{Powers of $i$}

One recurring theme is using four consecutive powers of $i$, for example, $1/i^2, 1/i, 1, i$. It's not always the same powers of $i$. No idea why four are needed.

\section{Length-Dependent}

\subsection{$\frac{i}{n}$}

\subsection{The Barcel√≥ Special}

Allows you to make your attention strict \AY{Need to cite}

\[\begin{bmatrix}
    \cos\left(\cfrac{\pi(1-2^{-i}}{10}\right)\\[3ex]
    \sin\left(\cfrac{\pi(1-2^{-i}}{10}\right)\\[3ex]
    (-1)^i
\end{bmatrix}\]