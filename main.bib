@inproceedings{vaswani-etal-2017-attention,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {Advances in Neural Information Processing Systems 30 (NeurIPS 2017)},
  year      = {2017},
  url       = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{arora+:2018,
  author = "Raman Arora and Amitabh Basu and Poorya Mianjy and Anirbit Mukherjee",
  title = "Understanding Deep Neural Networks with Rectified Linear Units",
  year = 2018,
  booktitle = "Proceedings of ICLR",
  url = "https://openreview.net/forum?id=B1J_rgWRW",
}

@inproceedings{merrill2024the,
    title={The Expressive Power of Transformers with Chain of Thought},
    author={William Merrill and Ashish Sabharwal},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=NjNGlPh8Wh}
}

@article{feng2024towards,
  title={Towards revealing the mystery behind chain of thought: a theoretical perspective},
  author={Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{akyurek2022learning,
  title={What learning algorithm is in-context learning? investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={arXiv preprint arXiv:2211.15661},
  year={2022}
}
